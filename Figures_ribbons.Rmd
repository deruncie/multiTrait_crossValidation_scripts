---
title: "Figures"
output: html_notebook
---


```{r}
library(ggplot2)
library(reshape2)
library(data.table)
```

```{r}
no_zero <- function(x) {
  not_NA = !is.na(x)
  y <- sprintf('%.1f',x)
  y[not_NA & x > 0 & x < 1] <- sprintf('.%s',x[not_NA & x > 0 & x < 1]*10)
  y[not_NA & x == 0] <- '0'
  y[not_NA & x > -1 & x < 0] <- sprintf('-.%s',x[not_NA & x > -1 & x < 0]*-10)
  y
}
SE = function(x) mean(x)/sqrt(length(x))

CI = function(x) {
  x = x[!is.na(x)]
  se = SE(x)
  mean = mean(x)
  data.frame(mean = mean,lower.CL = mean-1.96*se,upper.CL = mean+1.96*se)
}
```

```{r}
# results = readRDS('Results/collected_results_1level_theoretical.rds')
results = readRDS('Results/collected_results_1level.rds')
# results = readRDS('Results/collected_results_1level_big.rds')
```

```{r}
fix_results = function(results) {
  results$cor_Sib.1 = factor(results$cor_Sib.1)
  results$Method[results$Method == 'Joint'] = 'CV2'
  min_h2 = 0.02
  results$low_h2 = results$h2_correction < min_h2
  results$h2_correction = pmax(results$h2_correction,min_h2)
  # results$h2_correction[results$h2_correction != 1] = results$H2s.1[results$h2_correction != 1]
  # results$cov_correction[results$cov_correction == 1] = 0
  results$cor_std = results$cov / sqrt(results$var_uhat*results$var_pred)
  # results$cor_std[results$var_uhat*results$var_pred ==0] = 0  # protect against variance == 0 giving NA. Score these as cor==0
  results$cor_corrected = results$cor_std / sqrt(results$h2_correction)
  results$cor_corrected_cov = ((results$cov-results$cov_correction) / sqrt(results$var_uhat*results$var_pred)) / sqrt(results$h2_correction)
  # results$cov_correction2 = results$Rhat.2*results$Ghat.2 * (results$cov_correction!= 0)
  # results$cor_corrected_cov = ((results$cov-results$cov_correction2) / sqrt(results$var_uhat*results$var_pred)) / sqrt(results$h2_correction)
  results = subset(results,!Method == 'Joint_1step')
  
  # results$rho = results$cor_std
  results$rho = results$cor_corrected
  # results$rho = results$cor_corrected_cov
  results$rho[results$low_h2] = 0
  results$cor_corrected_cov[results$low_h2] = 0
  # results$rho = results$cov-results$cov_correction2
  
  results
}
```

```{r}
results = fix_results(results)
```


## Figure 1 True accuracy of methods
```{r}
n_Line. = 10 # 8
H2s.1. = 0.2 # 0.6
U_training_means = (as.data.table(subset(results,Data == 'U_training'  & cor_Family == .25 & H2s.1 == H2s.1. & n_Line == n_Line.))[,CI(rho),by=c('cor_G','cor_R','H2s.2','Method')])
```


### Figure 1 Accuracy of methods against U_train
```{r}
p_1a = ggplot(U_training_means,aes(x=cor_R,y=mean)) + 
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = rho[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  # ylab(expression(paste(rho()))) + 
  ylab(bquote(cor(hat(bold(u))[n1],bold(u)[n1]))) +
  xlab(expression(paste(rho[R]))) +
  # ggtitle(expression(paste('Accuracy measured against ',bold(u)[1],'*')))+
  # ylim(ylim) +
  scale_x_continuous(labels = no_zero) +
  theme(legend.position = 'bottom') + 
  geom_ribbon(aes(group = Method,fill=Method,ymin = lower.CL,ymax = upper.CL),alpha = 0.3) + 
  geom_line(aes(group = Method,color = Method));p_1a
```

```{r}
cowplot::save_plot('Paper/CrossValidation_GP/Figures/Figure_1.pdf',p_1a,base_width = 5)
```


## Figure 2 Estimated accuracy
```{r}
Y_training_ribbon = (as.data.table(subset(results,Data == 'Y_training'  & cor_Family == .25 & H2s.1 == H2s.1. & n_Line == n_Line.))[,CI(rho),by=c('cor_G','cor_R','H2s.2','Method')])
Uhat_training_ribbon = (as.data.table(subset(results,Data == 'Uhat_joint'  & cor_Family == .25 & H2s.1 == H2s.1. & n_Line == n_Line.))[,CI(rho),by=c('cor_G','cor_R','H2s.2','Method')])
ylim = range(c(Y_training_ribbon[,c('mean','lower.CL','upper.CL')],Uhat_training_ribbon[,c('mean','lower.CL','upper.CL')],U_training_means$rho))
```

### Figure 2a Accuracy of methods against Y_train
```{r}
p_2a = ggplot(Y_training_ribbon,aes(x=cor_R,y=mean)) + 
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = rho[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  # ylab(expression(paste(rho))) + xlab(expression(paste(sigma[R]))) +
  xlab(expression(rho[R])) + 
  ylab(bquote(cor(hat(bold(u))[n1],bold(y)[n1])~'/'~sqrt(hat(h^2)))) +
  # ggtitle(expression(paste('Accuracy measured against ',bold(y)[1],'*')))+
  coord_cartesian(ylim = pmin(1,ylim)) +
  # coord_cartesian(ylim = c(0.1,0.5)) +
  scale_x_continuous(labels = no_zero) +
  geom_ribbon(aes(group = Method,fill=Method,ymin = lower.CL,ymax = upper.CL),alpha = 0.3) + 
  geom_line(aes(group = Method,color = Method)) + 
  geom_line(data = U_training_means,aes(y=mean,group=Method,color=Method),linetype=2,size=.3)
p_2a
```


### Figure 2b Accuracy of methods against Uhat_joint
```{r}
p_2b = ggplot(Uhat_training_ribbon,aes(x=cor_R,y=mean)) + 
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = rho[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  # ylab(expression(paste(rho))) + 
  xlab(expression(paste(rho[R]))) +
  # ggtitle(expression(paste('Accuracy measured against ',bold(hat(u))[1],'*')))+
  ylab(bquote(rho(hat(bold(u))[n1],tilde(bold(u))[n1]))) +
  coord_cartesian(ylim = pmin(1,ylim)) +
  scale_x_continuous(labels = no_zero) +
  geom_ribbon(aes(group = Method,fill=Method,ymin = lower.CL,ymax = upper.CL),alpha = 0.2) + 
  geom_line(aes(group = Method,color = Method)) + 
  geom_line(data = U_training_means,aes(y=mean,group=Method,color=Method),linetype=2,size=.3)
p_2b
```


### Figure 2
```{r,fig.width=8,fig.height=6}
t = theme(strip.text.x = element_text(margin = margin()),strip.text.y = element_text(margin = margin()))
nl = theme(legend.position = 'none')
# p_1a+t
legend <- cowplot::get_legend(p_2a)
fig_2 = cowplot::plot_grid(p_2a+t+nl,p_2b+t+nl,legend,labels = c('A','B'),rel_widths = c(1,1,.2),nrow=1)
fig_2
cowplot::save_plot('Paper/CrossValidation_GP/Figures/Figure_2.pdf',fig_2,base_aspect_ratio = 2,base_width = 10)
```



## Figure 3 Model selection Joint vs single

```{r}
# Select best model between CV2 and Single for U_training
joint_vs_single_U_training = dcast(subset(results,Data == 'U_training'  & cor_Family == 0.25 & H2s.1 == H2s.1. & n_Line == n_Line. & !is.na(results$rho) & abs(results$rho) < 3),
                                runID + Rep + cor_G + cor_R + H2s.2 ~ Method,value.var = 'rho')
joint_vs_single_U_training$Select_joint_CV2 = joint_vs_single_U_training$CV2 > joint_vs_single_U_training$Single
joint_vs_single_U_training$Select_joint_CV1 = joint_vs_single_U_training$CV1 > joint_vs_single_U_training$Single
joint_vs_single_U_training$Select_CV2_vs_CV1 = joint_vs_single_U_training$CV2 > joint_vs_single_U_training$CV1


U_training_selection_CV1 = aggregate(Select_joint_CV1 ~ cor_G + cor_R + H2s.2,joint_vs_single_U_training,FUN=mean)
U_training_selection_CV1$Joint_best = U_training_selection_CV1$Select_joint_CV1 > 0.5
U_training_selection_CV2 = aggregate(Select_joint_CV2 ~ cor_G + cor_R + H2s.2,joint_vs_single_U_training,FUN=mean)
U_training_selection_CV2$Joint_best = U_training_selection_CV2$Select_joint_CV2 > 0.5
```


### Figure SX: When is CV2 better? When is CV1 better?
```{r}
p_S3a = ggplot(U_training_selection_CV1,aes(x=cor_R,y=Select_joint_CV1)) + 
  # ggtitle('Percent joint model better for predicting U in training data') +
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = rho[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  ylab('Fraction CV1 selected') + xlab(expression(paste(rho[R]))) +
  geom_hline(yintercept = 0.5) + coord_cartesian(ylim=c(0,1)) +
  geom_line()
p_S3a

p_S3b = ggplot(U_training_selection_CV2,aes(x=cor_R,y=Select_joint_CV2)) + 
  # ggtitle('Percent joint model better for predicting U in training data') +
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = rho[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  ylab('Fraction CV2 selected') + xlab(expression(paste(rho[R]))) +
  geom_hline(yintercept = 0.5) + coord_cartesian(ylim=c(0,1)) +
  geom_line()
p_S3b

p_S3 = cowplot::plot_grid(p_S3a,p_S3b,labels = c('A','B'))
cowplot::save_plot('Paper/CrossValidation_GP/Figures/SF0.pdf',p_S3,base_aspect_ratio = 2)
```

### Figure 3a: When is correct model selected with training data CV1?
```{r}
# Select best model between CV2 and Single for Y_training
joint_vs_single_Y_training_CV1 = dcast(subset(results,Data == 'Y_training'  & cor_Family == 0.25 & H2s.1 == H2s.1. & n_Line == n_Line.),
                                runID + Rep + cor_G + cor_R + H2s.2 ~ Method,value.var = 'rho')
joint_vs_single_Y_training_CV1$Select_joint = joint_vs_single_Y_training_CV1$CV1 > joint_vs_single_Y_training_CV1$Single
Y_training_selection = aggregate(Select_joint ~ cor_G + cor_R + H2s.2,joint_vs_single_Y_training_CV1,FUN=mean)

# percent of reps that best model was chosen

# joint_vs_single_Y_training_CV1 = merge(joint_vs_single_Y_training_CV1,joint_vs_single_U_training[,c('runID','Rep','cor_G','cor_R','H2s.2','Select_joint_CV1')])
# joint_vs_single_Y_training_CV1$Select_correct = !xor(joint_vs_single_Y_training_CV1$Select_joint_CV1,joint_vs_single_Y_training_CV1$Select_joint)

joint_vs_single_Y_training_CV1 = merge(joint_vs_single_Y_training_CV1,U_training_selection_CV1[,c('cor_G','cor_R','H2s.2','Joint_best')])
joint_vs_single_Y_training_CV1$Select_correct = !xor(joint_vs_single_Y_training_CV1$Joint_best,joint_vs_single_Y_training_CV1$Select_joint)


training_selection = aggregate(Select_correct ~ cor_G + cor_R + H2s.2,joint_vs_single_Y_training_CV1,FUN=mean)
p_3a = ggplot(training_selection,aes(x=cor_R,y=Select_correct)) + 
  # ggtitle('Percent correct model chosen using training individuals') +
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = rho[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  ylab('Fraction correct model selected\n(CV1 vs single)') + xlab(expression(paste(rho[R]))) +
  scale_x_continuous(labels = no_zero) +
  geom_hline(yintercept = 0.5) + coord_cartesian(ylim=c(0,1)) + 
  geom_line()
p_3a

```

### Figure 3b: When is correct model selected with training data?
```{r}
# Select best model between CV2 and Single for Y_training
joint_vs_single_Y_training_CV2 = dcast(subset(results,Data == 'Y_training'  & cor_Family == 0.25 & H2s.1 == H2s.1. & n_Line == n_Line.),
                                runID + Rep + cor_G + cor_R + H2s.2 ~ Method,value.var = 'rho')
joint_vs_single_Y_training_CV2$Select_joint = joint_vs_single_Y_training_CV2$CV2 > joint_vs_single_Y_training_CV2$Single
Y_training_selection = aggregate(Select_joint ~ cor_G + cor_R + H2s.2,joint_vs_single_Y_training_CV2,FUN=mean)

# percent of reps that best model was chosen
# joint_vs_single_Y_training_CV2 = merge(joint_vs_single_Y_training_CV2,joint_vs_single_U_training[,c('runID','Rep','cor_G','cor_R','H2s.2','Select_joint_CV2')])
# joint_vs_single_Y_training_CV2$Select_correct = !xor(joint_vs_single_Y_training_CV2$Select_joint_CV2,joint_vs_single_Y_training_CV2$Select_joint)
joint_vs_single_Y_training_CV2 = merge(joint_vs_single_Y_training_CV2,U_training_selection_CV2[,c('cor_G','cor_R','H2s.2','Joint_best')])
joint_vs_single_Y_training_CV2$Select_correct = !xor(joint_vs_single_Y_training_CV2$Select_joint,joint_vs_single_Y_training_CV2$Joint_best)

training_selection_CV2 = aggregate(Select_correct ~ cor_G + cor_R + H2s.2,joint_vs_single_Y_training_CV2,FUN=mean)
p_3b = ggplot(training_selection_CV2,aes(x=cor_R,y=Select_correct)) + 
  # ggtitle('Percent correct model chosen using training individuals') +
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = rho[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  ylab('Fraction correct model selected\n(CV2 vs single)') + xlab(expression(paste(rho[R]))) +
  scale_x_continuous(labels = no_zero) +
  geom_hline(yintercept = 0.5) + coord_cartesian(ylim=c(0,1)) + 
  geom_line()
p_3b
```


### Figure 3c: When is correct model selected with training data?
```{r}
# # Select best model between CV2 and Single for Y_training
# joint_CV2_vs_CV1_Y_training = dcast(subset(results,Data == 'Y_training'  & cor_Family == 0.25 & H2s.1 == H2s.1. & n_Line == n_Line.),
#                                 runID + Rep + cor_G + cor_R + H2s.2 ~ Method,value.var = 'rho')
# joint_vs_single_Y_training$Select_CV2 = joint_vs_single_Y_training$CV2 > joint_vs_single_Y_training$CV1
# # Y_training_selection = aggregate(Select_joint ~ cor_G + cor_R + H2s.2,joint_vs_single_Y_training,FUN=mean)
# 
# # percent of reps that best model was chosen
# joint_vs_single_Y_training$Select_correct = !xor(joint_vs_single_U_training$Select_CV2,joint_vs_single_Y_training$Select_joint)
# training_selection = aggregate(Select_correct ~ cor_G + cor_R + H2s.2,joint_vs_single_Y_training,FUN=mean)
# p_3b = ggplot(training_selection,aes(x=cor_R,y=Select_correct)) + 
#   # ggtitle('Percent correct model chosen using training individuals') +
#   facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = sigma[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
#   ylab('Fraction correct model selected (CV2 vs single)') + xlab(expression(paste(sigma[R]))) +
#   scale_x_continuous(labels = no_zero) +
#   geom_hline(yintercept = 0.5) + coord_cartesian(ylim=c(0,1)) + 
#   geom_line()
# p_3b
```


### Figure 3
```{r}
fig_3 = cowplot::plot_grid(p_3a,p_3b,labels = c('A','B'))
cowplot::save_plot('Paper/CrossValidation_GP/Figures/Figure_3.pdf',fig_3,base_aspect_ratio = 2,base_width = 10)
```





## Figure 4
This figure shows the success of cor_corrected_cov
```{r}
Y_training_means_cov_corrected = (as.data.table(subset(results,Data == 'Y_training'  & cor_Family == .25 & H2s.1 == H2s.1. & n_Line == n_Line.))[,CI(cor_corrected_cov),by=c('cor_G','cor_R','H2s.2','Method')])
# Y_training_means_cov_corrected = aggregate(cor_corrected_cov ~ cor_G + cor_R + H2s.2 + Method,subset(results,Data == 'Y_training'  & cor_Family == .25 & H2s.1 == H2s.1. & n_Line == n_Line.),FUN=mean)

ylim = range(c(Y_training_ribbon[,c('mean','lower.CL','upper.CL')],Y_training_means_cov_corrected[,c('mean','lower.CL','upper.CL')]))

p_4a = ggplot(subset(Y_training_means_cov_corrected, Method == 'CV2'),aes(x=cor_R,y=mean)) + 
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = rho[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  ylab(expression(paste(rho))) + xlab(expression(paste(rho[R]))) +
  ylab(bquote(rho[c](hat(bold(u))[n1],bold(y)[n1])~'/'~sqrt(h^2))) +
  # ggtitle(expression(paste('Accuracy measured against ',bold(y)[1],'*')))+
  ylim(ylim) +
  scale_x_continuous(labels = no_zero) +
  # geom_ribbon(data = subset(Y_training_ribbon,Method == 'CV2'),aes(ymin = lower.CL,ymax = upper.CL),alpha = 0.2) +
  # geom_ribbon(data = subset(U_training_means,Method == 'CV2'),aes(ymin = lower.CL,ymax = upper.CL),alpha = 0.2) + 
  geom_ribbon(aes(ymin = lower.CL,ymax = upper.CL),alpha = 0.2) + 
  geom_line() + 
  geom_line(data = subset(U_training_means,Method == 'CV2'),aes(y=mean),linetype=2,size=.3) +
  geom_line(data = subset(Y_training_ribbon, Method == 'CV2'),aes(y=mean),linetype = 3,size = 0.3) 
  # theme(legend.position = 'bottom')
p_4a
```


```{r}
# Select best model between CV2 and Single for Y_training
joint_vs_single_Y_training_cov_corrected = dcast(subset(results,Data == 'Y_training'  & cor_Family == 0.25 & H2s.1 == H2s.1. & n_Line == n_Line.),
                                runID + Rep + cor_G + cor_R + H2s.2 ~ Method,value.var = 'cor_corrected_cov')
joint_vs_single_Y_training_cov_corrected$Select_joint = joint_vs_single_Y_training_cov_corrected$CV2 > joint_vs_single_Y_training_cov_corrected$Single

# percent of reps that best model was chosen
# joint_vs_single_Y_training_cov_corrected = merge(joint_vs_single_Y_training_cov_corrected,joint_vs_single_U_training[,c('runID','Rep','cor_G','cor_R','H2s.2','Select_joint_CV2')])
# joint_vs_single_Y_training_cov_corrected$Select_correct = !xor(joint_vs_single_Y_training_cov_corrected$Select_joint_CV2,joint_vs_single_Y_training_cov_corrected$Select_joint)

joint_vs_single_Y_training_cov_corrected = merge(joint_vs_single_Y_training_cov_corrected,U_training_selection_CV2[,c('cor_G','cor_R','H2s.2','Joint_best')])
joint_vs_single_Y_training_cov_corrected$Select_correct = !xor(joint_vs_single_Y_training_cov_corrected$Select_joint,joint_vs_single_Y_training_cov_corrected$Joint_best)


training_selection_corrected = aggregate(Select_correct ~ cor_G + cor_R + H2s.2,joint_vs_single_Y_training_cov_corrected,FUN=mean)
training_selection = rbind(data.frame(Method = 'rho',training_selection_CV2),data.frame(Method = 'rho[c]',training_selection_corrected))
p_4b = ggplot(training_selection,aes(x=cor_R,y=Select_correct)) + 
  # ggtitle('Percent correct model chosen using training individuals') +
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = rho[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  ylab('Fraction correct model selected\n(CV2 vs single)') + xlab(expression(paste(rho[R]))) +
  scale_x_continuous(labels = no_zero) +
  # geom_line(data=training_selection_CV2,linetype = 2) + 
  geom_hline(yintercept = 0.5) + coord_cartesian(ylim=c(0,1)) + 
  scale_linetype_manual(values = c(2,1),labels = c(bquote(cor()),bquote(cor[c]())),name = 'Accuracy estimate') + 
  geom_line(aes(linetype = Method)) + 
  theme(legend.position = 'bottom')
p_4b
```


### Figure 4
```{r}
fig_4 = cowplot::plot_grid(p_4a,p_4b,labels = c('A','B'))
cowplot::save_plot('Paper/CrossValidation_GP/Figures/Figure_4.pdf',fig_4,base_aspect_ratio = 2,base_width = 10)
```

## Figure 5 CV2*

### Figure 5A Accuracy and Model selection for Joint vs single with sibs
```{r}

# U_validation_means = aggregate(rho ~ cor_G + cor_R + H2s.2 + cor_Sib.1 + Method,
#                                   subset(results,Data == 'U_Sib'  & cor_Family == 0.25 & H2s.1 == H2s.1. & n_Line == n_Line.),
#                                   FUN=mean)
# p_4a = ggplot(U_validation_means,aes(x=cor_R,y=rho)) + 
#   facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = sigma[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) + 
#   ylab(bquote(rho(hat(bold(underline(u)))[1]~'*,'~bold(u)[1]~'*'))) +
#   xlab(expression(paste(sigma[R]))) +
#   # ylim(ylim) + 
#   geom_line(aes(group = interaction(Method,cor_Sib.1,drop = T),color= factor(cor_Sib.1),linetype = Method)) +
#   guides(color = guide_legend(title = 'correlation of relative'))
# p_4a

# 
# 
# Y_validation_means = aggregate(rho ~ cor_G + cor_R + H2s.2 + cor_Sib.1,
#                                   subset(results,Data == 'Y_Sib' & Method == 'CV2'  & cor_Family == 0.25 & H2s.1 == H2s.1. & n_Line == n_Line.),
#                                   FUN=mean)
# Y_validation_means = rbind(data.frame(Y_validation_means,Predictand = 'Relatives'),
#                            data.frame(subset(Y_training_means,Method == 'CV2')[,-4],cor_Sib.1 = 1,Predictand = 'Training'))
# # U_training_means
# 
# p_5a = ggplot(Y_validation_means,aes(x=cor_R,y=rho)) + 
#   facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = sigma[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) + 
#   ylab(bquote(rho(hat(bold(underline(u)))[1]~'*,'~bold(underline(y))[1]~'*'))) +
#   xlab(expression(paste(sigma[R]))) +
#   # ylim(ylim) + 
#   scale_x_continuous(labels = no_zero) +
#   # geom_line(data = subset(Y_training_means,Method == 'Single'),color='black',linetype=2) + 
#   # geom_ribbon(aes(group = cor_Sib.1,fill=cor_Sib.1,ymin = lower.CL,ymax = upper.CL),alpha = 0.2) + 
#   geom_line(aes(group = interaction(Predictand,cor_Sib.1,drop = T),color= factor(cor_Sib.1),linetype = Predictand)) +
#   guides(color = guide_legend(title = 'correlation of relative'))
# p_5a


Y_validation_ribbon = (as.data.table(subset(results,Data == 'Y_Sib' & Method == 'CV2' & cor_Family == .25 & H2s.1 == H2s.1. & n_Line == n_Line.))[,CI(cor_corrected),by=c('cor_G','cor_R','H2s.2','cor_Sib.1')])
  # aggregate(rho ~ cor_G + cor_R + H2s.2 + cor_Sib.1,
  #                                 subset(results,Data == 'Y_Sib' & Method == 'CV2'  & cor_Family == 0.25 & H2s.1 == H2s.1. & n_Line == n_Line.),
  #                                 FUN=mean)
Y_validation_ribbon = rbind(data.frame(Y_validation_ribbon,Predictand = 'Relatives'),
                           data.frame(subset(Y_training_ribbon,Method == 'CV2')[,-4],cor_Sib.1 = 1,Predictand = 'Training'))
# U_training_means
ylim = range(c(Y_validation_ribbon$upper.CL,Y_validation_ribbon$lower.CL))

p_5a = ggplot(Y_validation_ribbon,aes(x=cor_R,y=mean)) + 
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = rho[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) + 
  ylab(bquote(rho(hat(bold(u))[n1],bold(y)[x1]))) +
  xlab(expression(paste(rho[R]))) +
  # ylim(ylim) + 
  coord_cartesian(ylim = pmin(1,ylim)) +
  scale_x_continuous(labels = no_zero) +
  geom_ribbon(data = subset(Y_validation_ribbon,Predictand == 'Relatives'),aes(group = cor_Sib.1,fill=cor_Sib.1,ymin = lower.CL,ymax = upper.CL),alpha = 0.2) + 
  geom_line(data = subset(Y_training_ribbon,Method == 'Single'),color='black',linetype=2) +
  geom_line(aes(group = interaction(Predictand,cor_Sib.1,drop = T),color= cor_Sib.1,linetype = Predictand)) +
  guides(color = guide_legend(title = 'correlation of relative'),fill = guide_legend(title = 'correlation of relative'))
p_5a


```

### Figure 5b
```{r}
# select models based on CV accuracy in Y
joint_vs_single_Y_validation = dcast(subset(results,Data == 'Y_Sib' & cor_Family == 0.25 & H2s.1 == H2s.1. & n_Line == n_Line.),
                                runID + Rep + cor_G + cor_R + H2s.2 + cor_Sib.1 ~ Method,value.var = 'rho')
joint_vs_single_Y_validation$Select_joint = joint_vs_single_Y_validation$CV2 > joint_vs_single_Y_validation$Single

# determine best model for each genetic architecture
# joint_vs_single_Y_validation = merge(joint_vs_single_Y_validation,joint_vs_single_U_training[,c('runID','Rep','cor_G','cor_R','H2s.2','Select_joint_CV2')])
# get averages
# joint_vs_single_Y_validation$Select_correct = !xor(joint_vs_single_Y_validation$Select_joint,joint_vs_single_Y_validation$Select_joint_CV2)

U_training_selection_CV2$Joint_best = U_training_selection_CV2$Select_joint > 0.5
joint_vs_single_Y_validation = merge(joint_vs_single_Y_validation,U_training_selection_CV2[,c('cor_G','cor_R','H2s.2','Joint_best')])
# get averages
joint_vs_single_Y_validation$Select_correct = joint_vs_single_Y_validation$Select_joint == joint_vs_single_Y_validation$Joint_best

#combine results
validation_selection = aggregate(Select_correct ~ cor_G + cor_R + H2s.2 + cor_Sib.1,joint_vs_single_Y_validation,FUN=mean)
validation_selection$Predictand = 'Relatives'
validation_selection = rbind(validation_selection,data.frame(training_selection_CV2,cor_Sib.1 = 1,Predictand = 'Training'))
validation_selection = rbind(validation_selection,data.frame(training_selection_corrected,cor_Sib.1 = 1,Predictand = 'Training_corrected'))

# plot
p_5b = ggplot(validation_selection,aes(x=cor_R,y=Select_correct)) + 
  # ggtitle('Percent correct model chosen using relatives for validation') +
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = rho[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  ylab('Fraction correct model selected\n(CV2 vs single)') + xlab(expression(paste(rho[R]))) + 
  scale_x_continuous(labels = no_zero) +
  geom_hline(yintercept = 0.5) + #coord_cartesian(ylim=c(0,1)) + 
  geom_line(aes(group = interaction(cor_Sib.1,Predictand,drop = T),color= cor_Sib.1,linetype=Predictand))
  # guides(color = guide_legend(title = 'correlation of relative'))
p_5b
```
### Figure 5

```{r}
# rc = 
cl = cowplot::get_legend(p_5a + theme(legend.position = 'top'))
# fig_4 = cowplot::plot_grid(cowplot::plot_grid(p_5a+theme(legend.position = 'top') + guides(color=F),p_4b+theme(legend.position = 'top') + guides(color=F),labels = c('A','B')),cl,ncol=1,labels = c('',''),rel_heights = c(1,.1))
fig_5 = cowplot::plot_grid(cowplot::plot_grid(p_5a+theme(legend.position = 'none'),p_5b+theme(legend.position = 'none'),labels = c('A','B')),cl,ncol=1,labels = c('',''),rel_heights = c(1,.1))
fig_5
cowplot::save_plot('Paper/CrossValidation_GP/Figures/Figure_5.pdf',fig_5,base_aspect_ratio = 2,base_width = 10)
```



## Supplements

```{r}
results_theoretical = readRDS('Results/collected_results_1level_theoretical.rds')
results_big = readRDS('Results/collected_results_1level_big.rds')
```

```{r}
results_theoretical = fix_results(results_theoretical)
results_big = fix_results(results_big)
```


### S1. 
Neither multi-trait model performed worse than the single-trait model when the true $\bG$ and $\bR$ matrices were used
```{r}
U_training_means_theoretical = (as.data.table(subset(results_theoretical,Data == 'U_training'  & cor_Family == .25 & H2s.1 == H2s.1. & n_Line == n_Line.))[,CI(rho),by=c('cor_G','cor_R','H2s.2','Method')])
p_s1 = ggplot(U_training_means_theoretical,aes(x=cor_R,y=mean)) + 
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = rho[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  # ylab(expression(paste(rho()))) + 
  ylab(bquote(rho(hat(bold(u))[n1],bold(u)[n1]))) +
  xlab(expression(paste(rho[R]))) +
  # ggtitle(expression(paste('Accuracy measured against ',bold(u)[1],'*')))+
  # ylim(ylim) +
  scale_x_continuous(labels = no_zero) +
  theme(legend.position = 'bottom') + 
  geom_ribbon(aes(ymin = lower.CL,ymax = upper.CL,group = Method,fill = Method),alpha = 0.2) + 
  geom_line(aes(group = Method,color = Method));
p_s1
```

### S2
The correction factor is nearly perfect when the true covariance matrices are used in place of their estimates
```{r}
Y_training_means_theoretical = (as.data.table(subset(results_theoretical,Data == 'Y_training'  & cor_Family == .25 & H2s.1 == H2s.1. & n_Line == n_Line.))[,CI(cor_corrected_cov),by=c('cor_G','cor_R','H2s.2','Method')])
p_s2 = ggplot(Y_training_means_theoretical,aes(x=cor_R,y=mean)) + 
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = rho[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  # ylab(expression(paste(rho))) + 
  xlab(expression(paste(rho[R]))) +
  ylab(bquote(cor[c](hat(bold(u))[n1],bold(y)[m1])~'/'~sqrt(hat(h^2)))) +
  # ggtitle(expression(paste('Accuracy measured against ',bold(y)[1],'*')))+
  # ylim(ylim) +
  scale_x_continuous(labels = no_zero) +
  geom_ribbon(aes(ymin = lower.CL,ymax = upper.CL,group = Method,fill = Method),alpha = 0.2) + 
  geom_line(aes(group = Method,color = Method)) + 
  geom_line(data = U_training_means_theoretical,aes(y=mean,group=Method,color=Method),linetype=2,size=.3)
p_s2
```

### S3.
if we increase the size of our simulated populations to 3000 individuals, which improves the quality of the covariance estimates, the correction factor is much more accurate
```{r}
n_Line. = 10
U_training_means_big = (as.data.table(subset(results_big,Data == 'U_training'  & cor_Family == .25 & H2s.1 == H2s.1. & n_Line == n_Line.))[,CI(cor_corrected_cov),by=c('cor_G','cor_R','H2s.2','Method')])
Y_training_means_big = (as.data.table(subset(results_big,Data == 'Y_training'  & cor_Family == .25 & H2s.1 == H2s.1. & n_Line == n_Line.))[,CI(cor_corrected_cov),by=c('cor_G','cor_R','H2s.2','Method')])
p_s3 = ggplot(Y_training_means_big,aes(x=cor_R,y=mean)) + 
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = rho[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  ylab(expression(paste(rho))) + xlab(expression(paste(rho[R]))) +
  ylab(bquote(cor[c](hat(bold(u))[n1],bold(y)[m1])~'/'~sqrt(hat(h^2)))) +
  # ggtitle(expression(paste('Accuracy measured against ',bold(y)[1],'*')))+
  # ylim(ylim) +
  scale_x_continuous(labels = no_zero) +
  geom_ribbon(aes(ymin = lower.CL,ymax = upper.CL,group = Method,fill = Method),alpha = 0.2) + 
  geom_line(aes(group = Method,color = Method)) + 
  geom_line(data = U_training_means_big,aes(y=mean,group=Method,color=Method),linetype=2,size=.3)
p_s3

```

### Supplements
```{r}
cowplot::save_plot('Paper/CrossValidation_GP/Figures/SF1.pdf',p_s1)
cowplot::save_plot('Paper/CrossValidation_GP/Figures/SF2.pdf',p_s2)
cowplot::save_plot('Paper/CrossValidation_GP/Figures/SF3.pdf',p_s3)
```


# Figure 5a
```{r}
results$rho_cov_corrected = results$cor_corrected_cov * (!results$low_h2)
Y_training_means_cov_corrected = aggregate(rho_cov_corrected ~ cor_G + cor_R + H2s.2 + Method,subset(results,Data == 'Y_training'  & cor_Family == .25 & H2s.1 == H2s.1. & n_Line == n_Line.),FUN=mean)
ylim = range(c(Y_training_means_cov_corrected$rho_cov_corrected,U_training_means$rho,Y_training_means$rho))

```

```{r}
p_5a = ggplot(subset(Y_training_means_cov_corrected,Method == 'CV2'),aes(x=cor_R,y=rho_cov_corrected)) + 
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = sigma[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  ylab(expression(paste(rho))) + xlab(expression(paste(sigma[R]))) +
  ylab(bquote(rho(hat(bold(u))[1]~'*,'~bold(y)[1]~'*'))) +
  # ggtitle(expression(paste('Accuracy measured against ',bold(y)[1],'*')))+
  # ylim(ylim) +
  coord_cartesian(ylim=ylim) + 
  scale_x_continuous(labels = no_zero) +
  scale_linetype_discrete(c('Estimated','Actual','Uncorrected'))+
  geom_line(aes(linetype = 'Estimated')) + 
  geom_line(data = subset(U_training_means,Method == 'CV2'),aes(y=rho,linetype = 'Actual'),size=.3) +
  geom_line(data = subset(Y_training_means,Method == 'CV2'),aes(y=rho,linetype = 'Uncorrected'),size=.3) +
  theme(legend.position = 'none')
p_5a
```

## Figure 5b
```{r}
# Select best model between CV2 and Single for U_training
joint_vs_single_U_training = dcast(subset(results,Data == 'U_training'  & cor_Family == 0.25 & H2s.1 == H2s.1. & n_Line == n_Line. & !is.na(results$rho) & abs(results$rho) < 3),
                                runID + Rep + cor_G + cor_R + H2s.2 ~ Method,value.var = 'rho_cov_corrected')
joint_vs_single_U_training$Select_joint_CV2 = joint_vs_single_U_training$CV2 > joint_vs_single_U_training$Single
U_training_selection_CV2 = aggregate(Select_joint_CV2 ~ cor_G + cor_R + H2s.2,joint_vs_single_U_training,FUN=mean)


# Select best model between CV2 and Single for Y_training
joint_vs_single_Y_training = dcast(subset(results,Data == 'Y_training'  & cor_Family == 0.25 & H2s.1 == H2s.1. & n_Line == n_Line.),
                                runID + Rep + cor_G + cor_R + H2s.2 ~ Method,value.var = 'rho_cov_corrected')
joint_vs_single_Y_training$Select_joint = joint_vs_single_Y_training$CV2 > joint_vs_single_Y_training$Single
# Y_training_selection = aggregate(Select_joint ~ cor_G + cor_R + H2s.2,joint_vs_single_Y_training,FUN=mean)

# percent of reps that best model was chosen
joint_vs_single_Y_training$Select_correct = !xor(U_training_selection_CV2$Select_joint_CV2,joint_vs_single_Y_training$Select_joint)
training_selection = aggregate(Select_correct ~ cor_G + cor_R + H2s.2,joint_vs_single_Y_training,FUN=mean)
p_5b = ggplot(training_selection,aes(x=cor_R,y=Select_correct)) + 
  # ggtitle('Percent correct model chosen using training individuals') +
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = sigma[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  ylab('Fraction correct model selected (CV2 vs single)') + xlab(expression(paste(sigma[R]))) +
  scale_x_continuous(labels = no_zero) +
  geom_hline(yintercept = 0.5) + coord_cartesian(ylim=c(0,1)) + 
  geom_line()
p_5b
```

## Figure 5
```{r}
fig_5 = cowplot::plot_grid(p_5a,p_5b,labels = c('A','B'))
fig_5
cowplot::save_plot('Paper/CrossValidation_GP/Figures/Figure_5.pdf',fig_5,base_aspect_ratio = 2,base_width = 10)
```

## Figure 2b
```{r,fig.width=8,fig.height=6}
fig_2 = cowplot::plot_grid(cowplot::plot_grid(p_2a,p_2b,labels = c('A','B')),p_3,ncol=1,labels = c('','C'))
# cowplot::plot_grid(p_2a,p_2b,p_3,NULL,ncol=2)
fig_2
cowplot::save_plot('Figures/Figure_2.pdf',fig_2,base_height = 6,base_aspect_ratio = 1.5)
```


## Figure S3 Model accuracy with Sibs
```{r}
U_validation_means = aggregate(rho ~ cor_G + cor_R + H2s.2 + cor_Sib.1 + Method,
                                  subset(results,Data == 'U_Sib'  & cor_Family == 0.25 & H2s.1 == H2s.1. & n_Line == n_Line.),
                                  FUN=mean)
Y_validation_means = aggregate(rho ~ cor_G + cor_R + H2s.2 + cor_Sib.1 + Method,
                                  subset(results,Data == 'Y_Sib'  & cor_Family == 0.25 & H2s.1 == H2s.1. & n_Line == n_Line.),
                                  FUN=mean)
ylim = range(c(U_validation_means$rho,Y_validation_means$rho))

```

```{r}
ggplot(U_validation_means,aes(x=cor_R,y=rho)) + 
  facet_grid(H2s.2~cor_G,labeller = labeller(.rows = label_both,.cols = label_both)) +
  ylim(ylim) + 
  geom_line(aes(group = interaction(Method,cor_Sib.1,drop = T),color= factor(cor_Sib.1),linetype = Method)) +
  guides(color = guide_legend(title = 'correlation of relative'))

```
```{r}
ggplot(Y_validation_means,aes(x=cor_R,y=rho)) + 
  facet_grid(H2s.2~cor_G,labeller = labeller(.rows = label_both,.cols = label_both)) +
  ylim(ylim) + 
  geom_line(aes(group = interaction(Method,cor_Sib.1,drop = T),color= factor(cor_Sib.1),linetype = Method)) +
  guides(color = guide_legend(title = 'correlation of relative'))

```


### Fig S2 - same for CV1
```{r}
# Select best model between CV1 and Single for U_training
joint_vs_single_U_training_CV1 = dcast(subset(results,Data == 'U_training'  & cor_Family == 0.25 & H2s.1 == H2s.1. & n_Line == n_Line.),
                                runID + Rep + cor_G + cor_R + H2s.2 ~ Method,value.var = 'rho')
joint_vs_single_U_training_CV1$Select_joint = joint_vs_single_U_training_CV1$CV1 > joint_vs_single_U_training_CV1$Single
U_training_selection_CV1 = aggregate(Select_joint ~ cor_G + cor_R + H2s.2,joint_vs_single_U_training_CV1,FUN=mean)

p_s2a = ggplot(U_training_selection_CV1,aes(x=cor_R,y=Select_joint)) + 
  ggtitle('Percent joint model better for predicting U in training data') +
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = sigma[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  ylab('Fraction joint model selected') + xlab(expression(paste(sigma[R]))) +
  geom_hline(yintercept = 0.5) + coord_cartesian(ylim=c(0,1)) +
  geom_line();p_s2a
```

```{r}
# Select best model between CV1 and Single for Y_training
joint_vs_single_Y_training = dcast(subset(results,Data == 'Y_training'  & cor_Family == 0.25 & H2s.1 == 0.2 & n_Line == 2),
                                runID + Rep + cor_G + cor_R + H2s.2 ~ Method,value.var = 'rho')
joint_vs_single_Y_training$Select_joint = joint_vs_single_Y_training$CV1 > joint_vs_single_Y_training$Single
Y_training_selection = aggregate(Select_joint ~ cor_G + cor_R + H2s.2,joint_vs_single_Y_training,FUN=mean)

# percent of reps that best model was chosen
joint_vs_single_Y_training$Select_correct = !xor(joint_vs_single_U_training_CV1$Select_joint,joint_vs_single_Y_training$Select_joint)
training_selection_CV1 = aggregate(Select_correct ~ cor_G + cor_R + H2s.2,joint_vs_single_Y_training,FUN=mean)
p_s2b = ggplot(training_selection_CV1,aes(x=cor_R,y=Select_correct)) + 
  ggtitle('Percent correct model chosen using training individuals and CV1') +
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = sigma[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  ylab('Fraction correct model selected') + xlab(expression(paste(sigma[R]))) +
  geom_hline(yintercept = 0.5) + coord_cartesian(ylim=c(0,1)) + 
  geom_line();p_s2b
```

### Figure 3a When is joint model better?
```{r}
# Select best model between CV2 and Single for U_training
joint_vs_single_U_training = dcast(subset(results,Data == 'U_training'  & cor_Family == 0.25 & H2s.1 == H2s.1. & n_Line == n_Line.),
                                runID + Rep + cor_G + cor_R + H2s.2 ~ Method,value.var = 'rho')
joint_vs_single_U_training$Select_joint = joint_vs_single_U_training$CV2 > joint_vs_single_U_training$Single
U_training_selection = aggregate(Select_joint ~ cor_G + cor_R + H2s.2,joint_vs_single_U_training,FUN=mean)

joint_vs_single_U_training$Select_joint = joint_vs_single_U_training$CV2 > joint_vs_single_U_training$Single
U_training_selection = aggregate(Select_joint ~ cor_G + cor_R + H2s.2,joint_vs_single_U_training,FUN=mean)
p_3a = ggplot(U_training_selection,aes(x=cor_R,y=Select_joint)) + 
  # ggtitle('Percent joint model better for predicting U in training data') +
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = sigma[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  ylab('Fraction joint model selected') + xlab(expression(paste(sigma[R]))) +
  geom_hline(yintercept = 0.5) + coord_cartesian(ylim=c(0,1)) +
  geom_line()
p_3a
```
### Figure 3b: When is correct model selected with training data?
```{r}
# Select best model between CV2 and Single for Y_training
joint_vs_single_Y_training = dcast(subset(results,Data == 'Y_training'  & cor_Family == 0.25 & H2s.1 == 0.2 & n_Line == 2),
                                runID + Rep + cor_G + cor_R + H2s.2 ~ Method,value.var = 'rho')
joint_vs_single_Y_training$Select_joint = joint_vs_single_Y_training$CV2 > joint_vs_single_Y_training$Single
Y_training_selection = aggregate(Select_joint ~ cor_G + cor_R + H2s.2,joint_vs_single_Y_training,FUN=mean)

# percent of reps that best model was chosen
joint_vs_single_Y_training$Select_correct = !xor(joint_vs_single_U_training$Select_joint,joint_vs_single_Y_training$Select_joint)
training_selection = aggregate(Select_correct ~ cor_G + cor_R + H2s.2,joint_vs_single_Y_training,FUN=mean)
p_3b = ggplot(training_selection,aes(x=cor_R,y=Select_correct)) + 
  # ggtitle('Percent correct model chosen using training individuals') +
  facet_grid(H2s.2~cor_G,labeller = label_bquote(cols = sigma[g]~'='~.(cor_G),rows=H^2~(2)~'='~.(H2s.2))) +
  ylab('Fraction correct model selected') + xlab(expression(paste(sigma[R]))) +
  geom_hline(yintercept = 0.5) + coord_cartesian(ylim=c(0,1)) + 
  geom_line()
p_3b
```

### Figure 3
```{r,fig.width=8}
cowplot::plot_grid(p_3a,p_3b,labels = c('A','B'))
```
